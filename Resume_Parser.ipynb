{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82249c1d-2182-49a4-a74a-2749d19361b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import requests\n",
    "import pandas as pd\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fadee926-9383-4d45-8e53-9061a78c06a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"\"\n",
    "file=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a53e39c5-6820-4cc2-a32c-5c957a39c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=fitz.open(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d502e06b-c511-46b3-9733-4315aecc3ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_spans(page_obj, page_number):\n",
    "    \"\"\"\n",
    "    Extracts text spans from a PDF page, handling encoded text if present.\n",
    "\n",
    "    Args:\n",
    "    - page_obj: The page object from which text is extracted.\n",
    "    - page_number: The page number for indexing.\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame containing the page number and extracted text.\n",
    "    \"\"\"\n",
    "    result_df = pd.DataFrame(columns=['page_num', 'text_content'])\n",
    "\n",
    "    try:\n",
    "        # Retrieve page dimensions and text\n",
    "        page_width = page_obj.rect.width\n",
    "        page_height = page_obj.rect.height\n",
    "        full_text_content = page_obj.get_text()\n",
    "        text_rows = []\n",
    "        blocks_dict = {page_number: page_obj.get_text('dict')['blocks']}\n",
    "        \n",
    "        for blocks in blocks_dict.values():\n",
    "            for block in blocks:\n",
    "                if block['type'] == 0:\n",
    "                    for line in block['lines']:\n",
    "                        for span in line['spans']:\n",
    "                            x_start, y_start, x_end, y_end = span['bbox']\n",
    "                            upper_margin = page_height * 0.07\n",
    "                            lower_margin = page_height * 0.9\n",
    "\n",
    "                            if y_start < upper_margin or y_end > lower_margin:\n",
    "                                continue\n",
    "                            \n",
    "                            span_text = unidecode(span['text'])\n",
    "                            if span_text.strip():\n",
    "                                text_rows.append((page_number, span_text.strip()))\n",
    "                                result_df = pd.DataFrame(text_rows, columns=['page_num', 'text_content'])\n",
    "        \n",
    "        return result_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print('An error occurred:', e)\n",
    "        return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb2d56cc-6dfe-45eb-8876-14a1b37ff731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelPrediction(prompt):\n",
    "    try:\n",
    "        prompt_encoded = prompt.encode('utf-8')\n",
    "        response = requests.post(url, data=prompt_encoded, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        try:\n",
    "            out = response.json()\n",
    "            return out\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error parsing response JSON: {e}\")\n",
    "            return {}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in model prediction: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a32aa19-e159-4ff1-bb21-ba748d239ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctSentences(file):\n",
    "    main_dictionary = {}\n",
    "    doc = fitz.open(file)\n",
    "    for i in range(len(doc)):\n",
    "        page = doc.load_page(i)\n",
    "        df = extract_text_spans(page, i)\n",
    "        span_texts = df['text_content'].tolist()\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are provided with a list of text spans extracted from a resume. Your task is to review each span for any grammatical errors, spelling mistakes, or inconsistencies, and provide a corrected version. Do not make changes that only involve expanding abbreviations (e.g., \"SQL\" to \"SQL (Structured Query Language)\"). If a span is already correct or only contains abbreviation expansions, simply return it unchanged. Here are the text spans:\n",
    "\n",
    "{span_texts}\n",
    "\n",
    "For each span, provide the corrected version in JSON format as follows. Only include sentences that have substantive changes:\n",
    "\n",
    "{{\n",
    "    \"original_span_1\": \"corrected_span_1\",\n",
    "    \"original_span_2\": \"corrected_span_2\",\n",
    "    ...\n",
    "}}\n",
    "\n",
    "### Examples\n",
    "\n",
    "**Input:**\n",
    "\n",
    "1. Managered a team of developers.\n",
    "2. Expert in Python, Java and ML.\n",
    "3. Completed project in less time.\n",
    "4. SQL is a database language.\n",
    "5. NLsP is a field in AI.\n",
    "\n",
    "**Output:**\n",
    "\n",
    "{{\n",
    "    \"Managered a team of developers.\": \"Managed a team of developers.\",\n",
    "    \"Completed project in less time.\": \"Completed the project in less time.\"\n",
    "}}\n",
    "\n",
    "Now, proceed with correcting the following text spans:\n",
    "\n",
    "{span_texts}\n",
    "\"\"\"\n",
    "        out = modelPrediction(prompt)\n",
    "        main_dictionary.update(out)\n",
    "    return main_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07f3cb86-d7a7-48c8-a693-f266df85ea68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ambitious, self-motivated professional with a passion for quality work. Seeking a baseline opportunity in Underwriting, Lending, Auditing, Quality Assurance, or Analyst roles. Possess a large spectrum of experience in the financial industry. I am a fast learner who values my employer.': 'Ambitious, self-motivated professional with a passion for quality work. Seeking a baseline opportunity in Underwriting, Lending, Auditing, Quality Assurance, or Analyst roles. I have a large spectrum of experience in the financial industry. I am a fast learner who values my employer.',\n",
       " 'Maintained beneath a 3% error ratio in all searches performed': 'Maintained an error ratio below 3% in all searches performed',\n",
       " 'Built knowledge about latest banking products and services through': 'Gained knowledge about the latest banking products and services',\n",
       " 'Analyzed customer credit history in order to determine customer willingness to pay and affordability for various payment plan options.': \"Analyzed the customer's credit history to determine their willingness to pay and affordability for various payment plan options.\",\n",
       " '* Booking and review of conventional, FHA. & VA. loans': '* Booking and review of conventional, FHA, and VA loans',\n",
       " '* Data entry functions including booking and review of recorded security instruments': '* Data entry functions: booking and reviewing recorded security instruments',\n",
       " '* Interpreted company policies while analyzing the applicant, property, and documentation to minimize the need for subsequent follow ups with borrowers': '* Interpreted company policies while analyzing applicant, property, and documentation to minimize the need for follow-ups with borrowers',\n",
       " 'Loan Processor 04/2003 to 08/2008 Company Name City, State': 'Loan Processor: 04/2003 to 08/2008 (Company Name, City, State)',\n",
       " '* Skills': 'Skills:'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correctSentences(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61f53f55-f465-41a8-a119-4ea05c35f806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "full_text=''\n",
    "for i in (0,len(doc)-1):\n",
    "    print(i)\n",
    "    page=doc.load_page(i)\n",
    "    full_text = full_text+'\\n\\n\\n\\n'+page.get_text()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ebc3ec-678b-41fa-a864-e2975f2b1615",
   "metadata": {},
   "source": [
    "# Extract Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266ccdea-3fa1-47b3-9f5d-02fda6b912d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Extract the following entities from the given text and provide the results in JSON format:\n",
    "\n",
    "1. Name: Extract names of individuals that are explicitly mentioned in the text only. Do not include names that are not present in the input. Do not extract deisgnations as names.\n",
    "2. Qualification: Extract only educational qualifications or Degrees mentioned in the text. Do not extract certifications or skills.\n",
    "3. Designation: Extract job titles or roles of individuals mentioned in the text only. Exclude departmental information.\n",
    "4. Phone Number: Extract telephone numbers in  formats mentioned in the text.\n",
    "5. Email: Extract email addresses in standard formats mentioned in the text.\n",
    "6. Address: Extract each part of addresses mentioned in the text. Include `Street`, `City`, and `State`.\n",
    "\n",
    "Ensure the output is only in JSON format and includes exactly these 6 categories, with empty lists for those without any entities. Do not include additional fields or information.\n",
    "\n",
    "Input: ```{full_text}```\n",
    "\"\"\"\n",
    "\n",
    "prompts=prompts.encode('utf-8')\n",
    "response = requests.post(url, data=prompts)\n",
    "print('response : ', response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce6bff4-b781-4565-9959-f6a72d5184c1",
   "metadata": {},
   "source": [
    "# Extract Roles and Responsibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7363d2e8-742c-42c4-8ec4-ddc609cf5af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = f\"\"\"\n",
    "**Instruction:** Extract the roles and responsibilities for each project from the resume. Format the output as a JSON object with the key \"Roles and Responsibilities\". Use only the information provided in the resume.\n",
    "\n",
    "**Input Resume:**\n",
    "\n",
    "{full_text}\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "[\n",
    "    {{\n",
    "        \"Roles and Responsibilities\": \"Lead developer responsible for backend development and database management.\"\n",
    "    }},\n",
    "    {{\n",
    "        \"Roles and Responsibilities\": \"Full-stack developer handling both frontend and backend development.\"\n",
    "    }},\n",
    "    {{\n",
    "        \"Roles and Responsibilities\": \"Developed the Android application and integrated RESTful APIs.\"\n",
    "    }}\n",
    "]\n",
    "\n",
    "\n",
    "prompts=prompts.encode('utf-8')\n",
    "response = requests.post(url, data=prompts)\n",
    "print('response : ', response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71638633-9bb2-494f-9c68-9dceb179e21c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "537d6f96-14ab-4425-a236-fdc0a98d80f2",
   "metadata": {},
   "source": [
    "# Tenure of Employment with previous companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a0bc755-19b5-433c-86cd-1405cf0fd429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\n",
      "  \"Company Name (Mortgage Banking Foreclosure Specialist)\": {\n",
      "    \"Start Date\": \"01/2014\",\n",
      "    \"End Date\": \"Present\"\n",
      "  },\n",
      "  \"Company Name (Consumer Underwriter II)\": {\n",
      "    \"Start Date\": \"10/2011\",\n",
      "    \"End Date\": \"12/2013\"\n",
      "  },\n",
      "  \"Company Name (Loan Document Specialist II)\": {\n",
      "    \"Start Date\": \"08/2008\",\n",
      "    \"End Date\": \"01/2010\"\n",
      "  },\n",
      "  \"Company Name (Mortgage Loan Operations)\": {\n",
      "    \"Start Date\": \"04/2003\",\n",
      "    \"End Date\": \"08/2008\"\n",
      "  }\n",
      "},\n",
      "\"Present\": {\n",
      "  \"Start Date\": \"YYYY-MM-DD\",\n",
      "  \"End Date\": \"YYYY-MM-DD\"\n",
      "}\n",
      "\n",
      "Replace YYYY-MM-DD with today's date before using the JSON object.\n"
     ]
    }
   ],
   "source": [
    "prompts2 = f\"\"\"\n",
    "You are an expert resume analyzer. Your task is to extract the start date and end date of employment for each company from the provided resume text.\n",
    "\n",
    "- Identify each company the candidate has worked for.\n",
    "- Extract and format the start date and end date of employment for each company.\n",
    "- If the end date is \"Present,\" replace it with today's date. Ensure that today's date is formatted as \"YYYY-MM-DD\".\n",
    "\n",
    "Your response should be strictly in JSON format, with no additional content or processing code. The format should be:\n",
    "\n",
    "{{\n",
    "  \"Company A\": {{\n",
    "    \"Start Date\": \"YYYY-MM-DD\",\n",
    "    \"End Date\": \"YYYY-MM-DD\" or today's date\n",
    "  }},\n",
    "  \"Company B\": {{\n",
    "    \"Start Date\": \"YYYY-MM-DD\",\n",
    "    \"End Date\": \"YYYY-MM-DD\" or today's date\n",
    "  }},\n",
    "  ...\n",
    "}}\n",
    "\n",
    "Input: ```{full_text}```\n",
    "\"\"\"\n",
    "prompts3=prompts2.encode('utf-8')\n",
    "response = requests.post(url, data=prompts3)\n",
    "print((response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5842abc6-cf6b-4401-9e7a-e889d51fc5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
